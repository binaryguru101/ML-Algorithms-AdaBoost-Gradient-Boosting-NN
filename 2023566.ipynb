{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a4a0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)        \n",
    "#\n",
    "# Verify Reading Dataset via MnistDataloader class\n",
    "#\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "# input_path = '../input'\n",
    "# training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "# training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "# test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "# test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "# training_images_filepath = r\"C:\\Users\\ujjwal\\Desktop\\sml\\train-images.idx3-ubyte\"\n",
    "# training_labels_filepath = r\"C:\\Users\\ujjwal\\Desktop\\sml\\train-labels.idx1-ubyte\"\n",
    "# test_images_filepath = r\"C:\\Users\\ujjwal\\Desktop\\sml\\t10k-images.idx3-ubyte\"\n",
    "# test_labels_filepath = r\"C:\\Users\\ujjwal\\Desktop\\sml\\t10k-labels.idx1-ubyte\"\n",
    "\n",
    "training_images_filepath = r\"train-images.idx3-ubyte\"\n",
    "training_labels_filepath = r\"train-labels.idx1-ubyte\"\n",
    "test_images_filepath = r\"t10k-images.idx3-ubyte\"\n",
    "test_labels_filepath = r\"t10k-labels.idx1-ubyte\"\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist_dataloader.load_data()\n",
    "\n",
    "print(type(training_images))\n",
    "\n",
    "\n",
    "\n",
    "training_images = np.array(training_images)\n",
    "test_images = np.array(test_images)\n",
    "training_labels = np.array(training_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "\n",
    "print((training_images.shape))\n",
    "print(type(training_images))\n",
    "#this data is not flattened therefore \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# training_images[0] = np.array(training_images[0])  # Convert list of arrays to a single NumPy array\n",
    "\n",
    "# print(training_images[0])  # Should print (28, 28)\n",
    "\n",
    "# plt.imshow(np.array(x_train[-1]), cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "print(f\"Training images shape: {training_images.shape}\")\n",
    "print(f\"Training labels shape: {training_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")\n",
    "\n",
    "\n",
    "train_index_0 = np.where(training_labels==0)[0]\n",
    "train_index_1 = np.where(training_labels==1)[0]\n",
    "\n",
    "train_index_0=train_index_0[:1000]\n",
    "train_index_1=train_index_1[:1000]\n",
    "\n",
    "train_indices = np.concatenate([train_index_0, train_index_1])\n",
    "\n",
    "X_train = training_images[train_indices]\n",
    "y_train = training_labels[train_indices]\n",
    "\n",
    "test_indices = np.where((test_labels == 0) | (test_labels == 1))[0]\n",
    "X_test = test_images[test_indices]\n",
    "y_test = test_labels[test_indices]\n",
    "\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4eebc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "def manual_pca(X, n_components=5):\n",
    "    # Center the data\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    \n",
    "    cov_matrix = np.cov(X_centered, rowvar=False)\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "    \n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    \n",
    "    components = eigenvectors[:, :n_components]\n",
    "    \n",
    "    X_pca = np.dot(X_centered, components)\n",
    "    \n",
    "    return X_pca, components, eigenvalues[:n_components]\n",
    "\n",
    "\n",
    "X_train_pca, pca_components, explained_var = manual_pca(X_train_flat, n_components=5)\n",
    "X_test_pca = np.dot(X_test_flat - np.mean(X_train_flat, axis=0), pca_components)\n",
    "\n",
    "print(X_train_pca.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857a0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.direction = 1  # 1 for < threshold = -1, else +1; -1 for reverse\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.ones(n_samples)\n",
    "        if self.direction == 1:\n",
    "            predictions[X[:, self.feature_index] < self.threshold] = -1\n",
    "        else:\n",
    "            predictions[X[:, self.feature_index] >= self.threshold] = -1\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709949ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, total_rounds=200):\n",
    "        self.total_rounds = total_rounds\n",
    "        self.stumps = []\n",
    "        self.stump_weights = []\n",
    "        self.train_errors = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y = np.where(y == 0, -1, 1)  # Convert labels to -1 and +1\n",
    "        sample_weights = np.ones(n_samples) / n_samples\n",
    "\n",
    "        for _ in range(self.total_rounds):\n",
    "            best_stump = None\n",
    "            best_error = float('inf')\n",
    "\n",
    "            for feature_index in range(n_features):\n",
    "                feature_values = X[:, feature_index]\n",
    "                thresholds = np.linspace(feature_values.min(), feature_values.max(), 3)\n",
    "\n",
    "                for threshold in thresholds:\n",
    "                    for direction in [1, -1]:\n",
    "                        stump = DecisionStump()\n",
    "                        stump.feature_index = feature_index\n",
    "                        stump.threshold = threshold\n",
    "                        stump.direction = direction\n",
    "\n",
    "                        preds = stump.predict(X)\n",
    "                        misclassified = (preds != y)\n",
    "                        error = np.sum(sample_weights * misclassified)\n",
    "\n",
    "                        if error < best_error:\n",
    "                            best_error = error\n",
    "                            best_stump = stump\n",
    "\n",
    "            # Compute alpha (stump weight)\n",
    "            eps = 1e-10  # To avoid division by zero\n",
    "            alpha = 0.5 * np.log((1 - best_error) / (best_error + eps))\n",
    "\n",
    "            # Update sample weights\n",
    "            preds = best_stump.predict(X)\n",
    "            sample_weights *= np.exp(-alpha * y * preds)\n",
    "            sample_weights /= np.sum(sample_weights)\n",
    "\n",
    "            # Store stump and its weight\n",
    "            self.stumps.append(best_stump)\n",
    "            self.stump_weights.append(alpha)\n",
    "            self.train_errors.append(best_error)\n",
    "\n",
    "    def predict(self, X):\n",
    "        stump_preds = np.array([alpha * stump.predict(X) for stump, alpha in zip(self.stumps, self.stump_weights)])\n",
    "        y_pred = np.sign(np.sum(stump_preds, axis=0))\n",
    "        y_pred[y_pred == 0] = 1  # Default to +1 if sign == 0\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55a408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5000\n",
      "Test Accuracy: 0.5371\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to binary (0 -> -1, 1 -> 1)\n",
    "y_train_boost = np.where(y_train == 0, -1, 1)\n",
    "y_test_boost = np.where(y_test == 0, -1, 1)\n",
    "\n",
    "# Initialize and train AdaBoost\n",
    "adaboost = AdaBoost()\n",
    "adaboost.fit(X_train_pca, y_train_boost)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "train_preds = adaboost.predict(X_train_pca)\n",
    "test_preds = adaboost.predict(X_test_pca)\n",
    "\n",
    "# Accuracy\n",
    "train_accuracy = np.mean(train_preds == y_train_boost)\n",
    "test_accuracy = np.mean(test_preds == y_test_boost)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
