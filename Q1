#
# This is a sample Notebook to demonstrate how to read "MNIST Dataset"
#
import numpy as np # linear algebra
import struct
from array import array
from os.path  import join

#
# MNIST Data Loader Class
#
class MnistDataloader(object):
    def __init__(self, training_images_filepath,training_labels_filepath,
                 test_images_filepath, test_labels_filepath):
        self.training_images_filepath = training_images_filepath
        self.training_labels_filepath = training_labels_filepath
        self.test_images_filepath = test_images_filepath
        self.test_labels_filepath = test_labels_filepath
    
    def read_images_labels(self, images_filepath, labels_filepath):        
        labels = []
        with open(labels_filepath, 'rb') as file:
            magic, size = struct.unpack(">II", file.read(8))
            if magic != 2049:
                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))
            labels = array("B", file.read())        
        
        with open(images_filepath, 'rb') as file:
            magic, size, rows, cols = struct.unpack(">IIII", file.read(16))
            if magic != 2051:
                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))
            image_data = array("B", file.read())        
        images = []
        for i in range(size):
            images.append([0] * rows * cols)
        for i in range(size):
            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])
            img = img.reshape(28, 28)
            images[i][:] = img            
        
        return images, labels
            
    def load_data(self):
        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)
        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)
        return (x_train, y_train),(x_test, y_test)        
#
# Verify Reading Dataset via MnistDataloader class
#

import random
import matplotlib.pyplot as plt

#
# Set file paths based on added MNIST Datasets
#
# input_path = '../input'
# training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')
# training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')
# test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')
# test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')

# training_images_filepath = r"C:\Users\ujjwal\Desktop\sml\train-images.idx3-ubyte"
# training_labels_filepath = r"C:\Users\ujjwal\Desktop\sml\train-labels.idx1-ubyte"
# test_images_filepath = r"C:\Users\ujjwal\Desktop\sml\t10k-images.idx3-ubyte"
# test_labels_filepath = r"C:\Users\ujjwal\Desktop\sml\t10k-labels.idx1-ubyte"

training_images_filepath = r"train-images.idx3-ubyte"
training_labels_filepath = r"train-labels.idx1-ubyte"
test_images_filepath = r"t10k-images.idx3-ubyte"
test_labels_filepath = r"t10k-labels.idx1-ubyte"



#
# Helper function to show a list of images with their relating titles
#
def show_images(images, title_texts):
    cols = 5
    rows = int(len(images)/cols) + 1
    plt.figure(figsize=(30,20))
    index = 1    
    for x in zip(images, title_texts):        
        image = x[0]        
        title_text = x[1]
        plt.subplot(rows, cols, index)        
        plt.imshow(image, cmap=plt.cm.gray)
        if (title_text != ''):
            plt.title(title_text, fontsize = 15);        
        index += 1

#
# Load MINST dataset
#
mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)
(training_images, training_labels), (test_images, test_labels) = mnist_dataloader.load_data()

print(type(training_images))



training_images = np.array(training_images)
test_images = np.array(test_images)
training_labels = np.array(training_labels)
test_labels = np.array(test_labels)


print((training_images.shape))
print(type(training_images))
#this data is not flattened therefore 




import numpy as np

# training_images[0] = np.array(training_images[0])  # Convert list of arrays to a single NumPy array

# print(training_images[0])  # Should print (28, 28)

# plt.imshow(np.array(x_train[-1]), cmap="gray")
# plt.show()

print(f"Training images shape: {training_images.shape}")
print(f"Training labels shape: {training_labels.shape}")
print(f"Test images shape: {test_images.shape}")
print(f"Test labels shape: {test_labels.shape}")


train_index_0 = np.where(training_labels==0)[0]
train_index_1 = np.where(training_labels==1)[0]

train_index_0=train_index_0[:1000]
train_index_1=train_index_1[:1000]

train_indices = np.concatenate([train_index_0, train_index_1])

X_train = training_images[train_indices]
y_train = training_labels[train_indices]

test_indices = np.where((test_labels == 0) | (test_labels == 1))[0]
X_test = test_images[test_indices]
y_test = test_labels[test_indices]

X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat = X_test.reshape(X_test.shape[0], -1)

def pca(X, num_components=5):
    # Center the data
    X_C= X - np.mean(X, axis=0)
    print(X_C.shape," shape of this is")
    S=(X_C @ X_C.T)/(X.shape[1]-1)
    eigval,eigvec=np.linalg.eigh(S)
    idx = eigval.argsort()[::-1]
    top_vectors = eigvec[:, idx[:num_components]]
    X_pca = X_C @ top_vectors

    return X_pca, eigval[idx], eigvec[:, idx]


X_train_pca = pca(X_train_flat, num_components=5)
X_test_pca = pca(X_test_flat, num_components=5)

# Convert labels: 0 → -1, 1 → 1 (AdaBoost expects this)
y_train_binary = np.where(y_train == 0, -1, 1)
y_test_binary = np.where(y_test == 0, -1, 1)


class DecisionStump:
    def __init__(self):
        self.feature_index = None
        self.threshold = None
        self.polarity = 1

    def predict(self, X):
        predictions = np.ones(X.shape[0])
        if self.polarity == 1:
            predictions[X[:, self.feature_index] < self.threshold] = -1
        else:
            predictions[X[:, self.feature_index] >= self.threshold] = -1
        return predictions


class AdaBoost:
    def __init__(self, n_clf=200):
        self.n_clf = n_clf
        self.clfs = []
        self.clf_weights = []
        self.train_errors = []
        self.train_losses = []

    def fit(self, X, y):
        n_samples, n_features = X.shape
        w = np.ones(n_samples) / n_samples

        for t in range(self.n_clf):
            clf = DecisionStump()
            min_error = float('inf')

            for feature_i in range(n_features):
                feature_vals = X[:, feature_i]
                thresholds = np.linspace(np.min(feature_vals), np.max(feature_vals), 4)[1:-1]
                for threshold in thresholds:
                    for polarity in [1, -1]:
                        predictions = np.ones(n_samples)
                        if polarity == 1:
                            predictions[feature_vals < threshold] = -1
                        else:
                            predictions[feature_vals >= threshold] = -1
                        error = np.sum(w[predictions != y])
                        if error < min_error:
                            clf.feature_index = feature_i
                            clf.threshold = threshold
                            clf.polarity = polarity
                            min_error = error

            EPS = 1e-10
            beta = 0.5 * np.log((1 - min_error + EPS) / (min_error + EPS))
            predictions = clf.predict(X)
            w *= np.exp(-beta * y * predictions)
            w /= np.sum(w)

            self.clfs.append(clf)
            self.clf_weights.append(beta)

            # Log training error and loss
            train_error = np.mean(predictions != y)
            train_loss = np.sum(w * (predictions != y))
            self.train_errors.append(train_error)
            self.train_losses.append(train_loss)

            print(f"Round {t+1}: error = {min_error:.4f}, beta = {beta:.4f}, train_error = {train_error:.4f}")

    def predict(self, X):
        clf_preds = [beta * clf.predict(X) for clf, beta in zip(self.clfs, self.clf_weights)]
        y_pred = np.sign(np.sum(clf_preds, axis=0))
        return y_pred
adaboost = AdaBoost(n_clf=200)
adaboost.fit(X_train_pca, y_train_binary)

y_pred_test = adaboost.predict(X_test_pca)
test_acc = np.mean(y_pred_test == y_test_binary)
print(f"Test Accuracy: {test_acc:.4f}")



                                           

